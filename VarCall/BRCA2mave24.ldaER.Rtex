%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Analysis of BRCA2 MAVE Data.      %%
%% Bi-normal, common variance Model. %%
%%     Annotated knitr doc           %%
%% Last Modified  05/17/24 by ESI.   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass{article}

%% begin.rcode setup, include=FALSE
% opts_chunk$set(fig.path='./figs/',cache.path='./cache/',child.path='../')
%% end.rcode

\input{preamble.tex}

\title{Analysis of BRCA2 MAVE Data Set\\ Bi--Normal, Common
  Variance Classification Model with \\ Batch Location And Scaling}
\author{Edwin Iversen}
\date{\today}
\begin{document}
\maketitle

\section{High--Level User--Specified Parameters}

%% begin.rcode
%  ## T degrees of freedom for measurement error model
%  t.df<-5
%  ## Do you want a test run with a 20% Subset?
%  subst<-FALSE
%  ## Choose Data Set:
%  db<-"uvCounts"
%  ## db<-"uvCountsFnl"
%  ##
%  ## Prior Probability Pathogenic, beta distribution parameters:
%  beta.a<-2.0
%  beta.b<-8.0  ##mean=0.20, ESS = 10
%  ## Set List of MCMC Control Parameters:
%  mcmc.pars<-list(iter=10000, ## short run
%                  burn=5000,
%                  thin=10)
%  ## mcmc.pars<-list(iter=150000, ## long run
%  ##                 burn=50000,
%  ##                 thin=10)
%  ##mcmc.pars<-list(iter=550000, ## longer run
%  ##                burn=50000,
%  ##                thin=25)
%% end.rcode

\section{Start Up}

Set a seed for the random number generators to ensure repeatabability
and load necessary R libraries.

%% begin.rcode
%  ## Set Random Seed
%  set.seed(seed=03122024)
%  ## Load custom functions that will be used below:
%  source("RFuncs.R",echo=FALSE)
%  ## Libraries:
%  ##library(coda)
%  library(rjags)
%  library(R2WinBUGS)
%  library(R2jags)
%  library(mgcv)
%% end.rcode

\section{Import Data}

Read in the MAVE data and training variant labels:

%% begin.rcode
%  if (db=="uvCounts"){
%    uvDB<-read.delim("combined.raw.20.tsv")
%  }
%  if (db=="uvCountsFnl"){
%    uvDB<-read.delim("combined.raw.tsv")
%  }
%  dim(uvDB)
%  if (subst==TRUE) uvDB<-uvDB[seq(1,nrow(uvDB),by=5),]
%  dim(uvDB)
%  ## use StopGain vs Synonymous for Training lables:
%  newTrainingLabel<-read.csv("variant_type_for_train.csv")
%  kdel<-unique(newTrainingLabel$uPOS[newTrainingLabel$EventType=="StopGain"])
%  kneut<-unique(newTrainingLabel$uPOS[newTrainingLabel$EventType=="Synonymous"])
%  uvDB$label<-rep(NA,nrow(uvDB))
%  uvDB$label[uvDB$uPOS %in% kdel]<-"P"
%  uvDB$label[uvDB$uPOS %in% kneut]<-"B"
%  head(uvDB)
%% end.rcode

\section{DB Row Column Names}

Add row names; change a few column names; make `Exon' a factor:

%% begin.rcode
%  if ((db=="uvCounts")|(db=="uvCountsFnl")){
%     colnames(uvDB)[colnames(uvDB)=="class"]<-"classification"
%     colnames(uvDB)[colnames(uvDB)=="exon"]<-"Exon"
%     colnames(uvDB)[colnames(uvDB)=="PB"]<-"P_B"
%     ## Annotation DB:
%     annot<-uvDB[,c(1:23,42:43)]
%  }
%  if (nrow(uvDB)==length(unique(uvDB$uPOS))) rownames(uvDB)<-uvDB$uPOS
%  uvDB$Exon<-factor(uvDB$Exon)
%% end.rcode

\subsection{Compute Offsets and Other Summaries for Counts Data}

Compute count totals for all observed combinations of day, exon and
replicate (labeled `offsets' in the code below), then use these to
compute raw abundance rates (denoted $A_{v,r,d}$ in the
Supplement). Use the abundance rates to compute day 14 to day 5 and
day 14 to day 0 (lib) rate ratios (denoted $R_{v,r}^{14:5}$ and
$R_{v,r}^{14:0}$, respectively, in the Supplement).  Add columns
containing the `offsets' and the two rate ratios to the working data
base {\texttt{uvDB}}.  Finally, compute an exon--specific standardized
position variable {\texttt{PosStd}} and add it to the working data
base.

%% begin.rcode
% if ((db=="uvCounts")|(db=="uvCountsFnl")){
%   cnames<-colnames(uvDB)
%   lcnames<-nchar(cnames)
%   daylib<-cnames[substr(cnames,lcnames-2,lcnames)=="lib"]
%   day5<-cnames[substr(cnames,lcnames-1,lcnames)=="D5"]
%   day14<-cnames[substr(cnames,lcnames-2,lcnames)=="D14"]
%   offsetlib<-matrix(NA,nrow(uvDB),length(daylib))
%   colnames(offsetlib)<-cnOffsetLib<-paste0("R",1:6,"offsetLib")
%   offset5<-matrix(NA,nrow(uvDB),length(day5))
%   colnames(offset5)<-cnOffset5<-paste0("R",1:6,"offsetD5")
%   offset14<-matrix(NA,nrow(uvDB),length(day14))
%   colnames(offset14)<-cnOffset14<-paste0("R",1:6,"offsetD14")
%   for (i in 1:length(day5)){
%       templib<-lapply(split(uvDB[,daylib[i]],uvDB$Exon),sum,na.rm=TRUE)
%       temp5<-lapply(split(uvDB[,day5[i]],uvDB$Exon),sum,na.rm=TRUE)
%       temp14<-lapply(split(uvDB[,day14[i]],uvDB$Exon),sum,na.rm=TRUE)
%       offsetlib[,i]<-as.numeric(templib[uvDB$Exon])
%       offset5[,i]<-as.numeric(temp5[uvDB$Exon])
%       offset14[,i]<-as.numeric(temp14[uvDB$Exon])
%   }
%   rawlib<-(uvDB[,daylib]/offsetlib)  ## lib (day 0) abundance rates
%   raw5<-(uvDB[,day5]/offset5)        ## day 5 abundance rates
%   raw14<-(uvDB[,day14]/offset14)     ## day 14 abundance rates
%   raw<-(raw14/raw5)                  ## day 14 to day 5 rate ratio
%   raw2<-(raw14/rawlib)               ## day 15 to day 0 rate ratio
%   colnames(raw)<-paste0("R",1:6,"_raw")
%   colnames(raw2)<-paste0("R",1:6,"_rawlib")
%   uvDB<-cbind(uvDB,offsetlib,offset5,offset14,raw,raw2)
%   rm(offsetlib,offset5,offset14,lcnames,raw,raw2,rawlib,raw5,raw14)
%   pos.min<-lapply(split(uvDB[,"POS"],uvDB$Exon),min,na.rm=TRUE)
%   pos.max<-lapply(split(uvDB[,"POS"],uvDB$Exon),max,na.rm=TRUE)
%   pos.range<- as.numeric(pos.max) - as.numeric(pos.min)
%   names(pos.range)<-names(pos.min)
%   uvDB$PosMin<-as.numeric(pos.min[uvDB$Exon])
%   uvDB$PosMax<-as.numeric(pos.max[uvDB$Exon])
%   uvDB$PosRange<-as.numeric(pos.range[uvDB$Exon])
%   uvDB$PosStd<-((uvDB$POS - uvDB$PosMin)/(uvDB$PosMax - uvDB$PosMin))
%   summary(uvDB$PosStd)
% }
%% end.rcode
 
\section{Exploratory Data Analysis}

\subsection{Tabular Summaries}

Cross--tabulations of several design and annotation variables:

%% begin.rcode
%  table(uvDB$Exon,uvDB$EventType,useNA="always")
%  table(uvDB$Exon,uvDB$P_B,useNA="always")
%  ##table(uvDB$EventType,uvDB$spliceR,useNA="always")
%  table(uvDB$P_B,uvDB$classification)
%  table(uvDB$label,uvDB$classification)
%  ##table(uvDB$EventType,uvDB$spliceR)
%  table(uvDB$EventType,uvDB$classification)
%% end.rcode

\newpage
\subsection{Graphical Summaries of Labeled Data}

Histograms of: (1) the replicate 1 day 14 to day 5 rate ratio, (2) the
median day 14 to day 5 rate ratio across replicates and (3) the median
day 14 to day 0 (not yet positionally normalized) rate ratio.

%% begin.rcode, fig.width=7.5, fig.height=9.5
%  par(mfrow=c(3,1))
%  plot(c(0,3.5),c(0,2.5),las=1,xlab="R1_Raw",ylab="Probability",type="n",
%      ,main="Histogram of Labelled Rep1 D14/D5 Ratios by Class")
%  hist(uvDB$R1_raw[(!is.na(uvDB$P_B))&(uvDB$P_B=="B")],
%       col=3,prob=TRUE,nclass=30,add=TRUE)
%  hist(uvDB$R1_raw[(!is.na(uvDB$P_B))&(uvDB$P_B=="P")],
%       col=2,prob=TRUE,nclass=30,add=TRUE)
%  legend("topleft",inset=0.05,legend=c("Benign","Pathogenic"),
%         col=c(3,2),lwd=5)
%  ## Median of Raw D14/D5 Ratios:
%  uvDB$rawMedn<-apply(uvDB[,c("R1_raw","R2_raw","R3_raw","R4_raw","R5_raw","R6_raw")],
%                        1,FUN=median,na.rm=TRUE)
%  plot(c(0,3.5),c(0,2.5),las=1,xlab="rawMedn",ylab="Probability",type="n",
%      ,main="Histogram of Labelled Raw Median D14/D5 Ratios by Class")
%  hist(uvDB$rawMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="B")],
%       col=3,prob=TRUE,nclass=30,add=TRUE)
%  hist(uvDB$rawMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="P")],
%       col=2,prob=TRUE,nclass=30,add=TRUE)
%  legend("topleft",inset=0.05,legend=c("Benign","Pathogenic"),
%         col=c(3,2),lwd=5)
%  ## Median of Raw Day14/lib Ratios 
%  uvDB$rawLibMedn<-apply(uvDB[,c("R1_rawlib","R2_rawlib","R3_rawlib","R4_rawlib",
%                                 "R5_rawlib","R6_rawlib")],
%                          1,FUN=median,na.rm=TRUE)
%  plot(c(0,3.5),c(0,2.5),las=1,xlab="ceNormMedn",ylab="Probability",type="n",
%      ,main="Histogram of Labelled Day14/Lib Median Ratios by Class")
%  hist(uvDB$rawLibMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="B")],
%       col=3,prob=TRUE,nclass=30,add=TRUE)
%  hist(uvDB$rawLibMedn[(!is.na(uvDB$P_B))&(uvDB$P_B=="P")],
%       col=2,prob=TRUE,nclass=30,add=TRUE)
%  legend("topleft",inset=0.05,legend=c("Benign","Pathogenic"),
%         col=c(3,2),lwd=5)
%% end.rcode

\newpage
\section{Create `Tall' Data Structure}

Here we create a stacked data structure with day-- and
replicate--specific measurments in different rows and the variant
counts and batch totals (`offsets') each in their own column.  This
format is needed modeling.  Save the old {\texttt{uvDB}} as
{\texttt{uvMaster}} and save the stacked data structure as the new
{\texttt{uvDB}}. Convert categorical variables from character to
factor types.

%% begin.rcode
%  uvMaster<-uvDB
%  uvDB<-uvDB[,c("uPOS","PosStd","Exon","P_B","label","EventType",day5,day14,daylib,cnOffset5,cnOffset14,cnOffsetLib)]
%  rownames(uvDB)<-NULL
%  temp<-uvDB
%  n<-nrow(temp)
%  tall<-NULL
%  for (i in 1:6){
%    replic<-paste0("R",i)
%    d5<-cbind(as.matrix(temp[,c("uPOS","PosStd","Exon","P_B","label","EventType",day5[i],cnOffset5[i])]),
%              rep("D5",n),rep(replic,n))
%    d14<-cbind(as.matrix(temp[,c("uPOS","PosStd","Exon","P_B","label","EventType",day14[i],cnOffset14[i])]),
%              rep("D14",n),rep(replic,n))
%    d0<-cbind(as.matrix(temp[,c("uPOS","PosStd","Exon","P_B","label","EventType",daylib[i],cnOffsetLib[i])]),
%              rep("D0",n),rep(replic,n))
%    colnames(d0)<-colnames(d5)<-colnames(d14)<-NULL
%    tall<-rbind(tall,d0,d5,d14)
%  }
%  uvDB<-data.frame(tall)
%  rm(temp)
%  colnames(uvDB)<-c("variant","PosStd","Exon","p.b","label","eventtype","count","offset","day","replicate")
%  uvDB$PosStd<-as.numeric(uvDB$PosStd)
%  uvDB$count<-as.numeric(uvDB$count)
%  uvDB$offset<-as.numeric(uvDB$offset)
%  uvDB<-uvDB[!is.na(uvDB$count),]
%  uvDB$day<-factor(uvDB$day)
%  uvDB$replicate<-factor(uvDB$replicate)
%  uvDB$variant<-factor(uvDB$variant)
%  uvDB$Exon<-factor(uvDB$Exon)
%  uvDB$p.b<-factor(uvDB$p.b)
%  uvDB$p.b<-factor(uvDB$label)
%  uvDB$batchE<-as.numeric(uvDB$Exon)   ## batch=exon
%  ## Exon by Rep
%  uvDB$ER<-paste0(substr(uvDB$Exon,1,4),uvDB$replicate)
%  uvDB$ER<-factor(uvDB$ER)
%  uvDB$batch<-as.numeric(uvDB$ER)  ## More refined batch variable
%  table(uvDB$ER)
%  table(uvDB$batch)
%  head(uvDB)
%  summary(uvDB)
%%  end.rcode

\newpage
\section{Positional Normalization}

Computations in support of the positional normalization of the day 0
(lib) counts to the day 5 values.  Two methods for computing the
positional correction are implemented here: by exon and by exon and
replicate.  We use the latter approach; the former is not used.

\subsubsection{Data Processing}

Create a data structure ({\texttt{uvNorm}}) for the normalization
model.  Compute the day 5 to day 0 rate ratio $R^{5:0}$ for the model
and subset to variants such that $R^{5:0} \,>\,0.5$ or $R^{14:5}
\,>\,0.8$.

%% begin.rcode
%  tall<-data.frame(tall)
%  colnames(tall)<-c("variant","PosStd","Exon","p.b","label","eventtype","count","offset","day","replicate")
%  ## Exon by Rep
%  tall$ER<-paste0(substr(tall$Exon,1,4),tall$replicate)
%  table(tall$ER)
%  table(tall$eventtype)
%  table(tall$day)
%  uvD0<-tall[tall$day=="D0",]
%  uvD5<-tall[tall$day=="D5",]
%  uvD14<-tall[tall$day=="D14",]
%  table((uvD0$variant==uvD5$variant)&(uvD0$Exon==uvD5$Exon)&(uvD0$replicate==uvD5$replicate))
%  table((uvD14$variant==uvD5$variant)&(uvD14$Exon==uvD5$Exon)&(uvD14$replicate==uvD5$replicate))
%  uvD0$rawR<-(as.numeric(uvD0$count)/as.numeric(uvD0$offset))
%  uvD5$rawR<-(as.numeric(uvD5$count)/as.numeric(uvD5$offset))
%  uvD14$rawR<-(as.numeric(uvD14$count)/as.numeric(uvD14$offset))
%  uvD5$R14.5<-(uvD14$rawR/uvD5$rawR)
%  uvD5$R5.0<-(uvD5$rawR/uvD0$rawR)
%  R14.5<-lapply(split(uvD5[,"R14.5"],uvD5$variant),mean,na.rm=TRUE)
%  R14.5<-unlist(R14.5)
%  R5.0<-lapply(split(uvD5[,"R5.0"],uvD5$variant),mean,na.rm=TRUE)
%  R5.0<-unlist(R5.0)
%  table(names(R14.5)==names(R5.0))
%  ## Subset of Variants to Use for Positional Normalization of Lib Values
%  posTrainVariants<-names(R5.0)[(R14.5>0.8)|(R5.0>0.5)]
%  length(posTrainVariants)
%  keep<-(uvD5$variant %in% posTrainVariants)
%  ## Ratio for Positional Normalization Analysis:
%  uvD5$Ratio<-(as.numeric(uvD5$count)/as.numeric(uvD5$offset))
%  uvD5$Ratio<-uvD5$Ratio/(as.numeric(uvD0$count)/as.numeric(uvD0$offset))
%  summary(uvD5$Ratio)
%  ##keep<-((uvD5$eventtype=="Synonymous")|(uvD5$eventtype=="Missense"))
%  keep<-(keep&(!is.na(uvD5$Ratio)))
%  uvNorm<-uvD5[keep,]
%  uvNorm$Exon<-as.factor(uvNorm$Exon)
%  uvNorm$PosStd<-as.numeric(uvNorm$PosStd)
%  uvNorm$lRatio<-log(uvNorm$Ratio)
%% end.rcode

\subsubsection{Normalization By Exon, Combining Replicates (Not Used)}

Implement the exon--by--exon normalization scheme and generate
plots of the data and the estimated positional normalization curve.

%% begin.rcode, posFit1-cache, cache=TRUE, cache.lazy=FALSE
%   gam.pos<-mgcv::gam(lRatio ~  s(PosStd,bs="ad",by=Exon),data=uvNorm)
%   gam.pos2<-mgcv::gam(lRatio ~ s(PosStd,bs="tp",by=Exon),data=uvNorm)
%   temp<-predict(gam.pos,newdata=uvNorm,se.fit=TRUE)
%   uvNorm$adSmooth<-temp$fit
%   uvNorm$adSmoothSE<-temp$se.fit 
%   temp<-predict(gam.pos2,newdata=uvNorm,se.fit=TRUE)
%   uvNorm$tpSmooth<-temp$fit
%   uvNorm$tpSmoothSE<-temp$se.fit
%   posFits<-unique(uvNorm[,c("variant","Exon","PosStd","adSmooth","adSmoothSE",
%                             "tpSmooth","tpSmoothSE")])
%   uExon<-unique(as.character(uvNorm$Exon))
%   nExon<-length(uExon)
%   pdf("SmoothFitsFnl.pdf",height=8.5,width=11)
%   par(mfrow=c(2,1))
%   ## Adaptive Smoooth
%   for (i in 1:nExon){
%   plot(uvNorm$PosStd[uvNorm$Exon==uExon[i]],
%        uvNorm$lRatio[uvNorm$Exon==uExon[i]],las=1,
%        ylab="logRatio",xlab="Standardized Position",
%        main=paste0("Adaptive Smooth Fit to Exon ",uExon[i]),xlim=c(0,1.12))
%   uRep<-unique(uvNorm$replicate[(uvNorm$Exon==uExon[i])])
%   for (j in 1:length(uRep)){
%     points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          col=j,pch=16)
%   }
%   ##points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     col=3,pch=16)
%   legend("topright",inset=0.01,col=c(1:length(uRep)),lwd=5,legend=uRep)
%   ##legend("topright",inset=0.05,col=c(1,3),lwd=5,legend=c("Missense","Synonymous"))
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$adSmooth[posFits$Exon==uExon[i]],col=2,lwd=3)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$adSmooth[posFits$Exon==uExon[i]]+2*posFits$adSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$adSmooth[posFits$Exon==uExon[i]]-2*posFits$adSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   ## Thin Plate Smoooth
%   plot(uvNorm$PosStd[uvNorm$Exon==uExon[i]],
%        uvNorm$lRatio[uvNorm$Exon==uExon[i]],las=1,
%        ylab="logRatio",xlab="Standardized Position",
%        main=paste0("Thin Plate Smooth Fit to Exon ",uExon[i]),
%        type="n",xlim=c(0,1.12))
%   for (j in 1:length(uRep)){
%     points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j])],
%          col=j,pch=16)
%   }
%   ##points(uvNorm$PosStd[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     uvNorm$lRatio[(uvNorm$Exon==uExon[i])&(uvNorm$eventtype=="Synonymous")],
%   ##     col=3,pch=16)
%   legend("topright",inset=0.01,col=c(1:length(uRep)),lwd=5,legend=uRep)
%   ##legend("topright",inset=0.05,col=c(1,3),lwd=5,legend=c("Missense","Synonymous"))
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$tpSmooth[posFits$Exon==uExon[i]],col=2,lwd=3)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$tpSmooth[posFits$Exon==uExon[i]]+2*posFits$tpSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   lines(posFits$PosStd[posFits$Exon==uExon[i]],
%         posFits$tpSmooth[posFits$Exon==uExon[i]]-2*posFits$tpSmoothSE[posFits$Exon==uExon[i]],
%         col=2,lwd=3,lty=2)
%   }
%   dev.off()
%% end.rcode

\subsubsection{Normalization By Exon and Replicate (This Method Used)}

Implement the exon by replicate normalization scheme and generate
plots of the data and the estimated positional normalization curve.

%% begin.rcode, posFit2-cache, cache=TRUE, cache.lazy=FALSE
%   uvNorm$adSmooth<-rep(NA,nrow(uvNorm))
%   uvNorm$adSmoothSE<-rep(NA,nrow(uvNorm))
%   uvDB$adSmooth<-rep(NA,nrow(uvDB))
%   uvDB$adSmoothSE<-rep(NA,nrow(uvDB))
%   pdf("SmoothFitsByRepFnl.pdf",height=8.0,width=24)
%   par(mfrow=c(1,1))
%   ## Adaptive Smoooth -- Independent Fits by Exon and Replicate
%   for (i in 1:nExon){
%       plot(uvNorm$PosStd[uvNorm$Exon==uExon[i]],
%            uvNorm$lRatio[uvNorm$Exon==uExon[i]],las=1,
%            ylab="logRatio",xlab="Standardized Position",
%            main=paste0("Replicate-Specific Adaptive Smooth Fit to Exon ",uExon[i]),
%            xlim=c(0,1.12))
%       uRep<-unique(uvNorm$replicate[(uvNorm$Exon==uExon[i])])  ##unique replicate IDs
%       for (j in 1:length(uRep)){
%           keep<-((uvNorm$Exon==uExon[i])&(uvNorm$replicate==uRep[j]))
%           gam.pos<-mgcv::gam(lRatio ~  s(PosStd,bs="ad",by=Exon),data=uvNorm[keep,])
%           temp<-predict(gam.pos,newdata=uvNorm[keep,],se.fit=TRUE)
%           uvNorm$adSmooth[keep]<-temp$fit
%           uvNorm$adSmoothSE[keep]<-temp$se.fit
%           points(uvNorm$PosStd[keep],uvNorm$lRatio[keep],col=j,pch=16)
%           posFits<-unique(uvNorm[keep,c("variant","Exon","PosStd","adSmooth","adSmoothSE")])
%           lines(posFits$PosStd,posFits$adSmooth,col=j,lwd=5)
%           ##lines(posFits$PosStd,posFits$adSmooth + 2*posFits$adSmoothSE,
%           ##      col=j,lwd=3,lty=2)
%           ##lines(posFits$PosStd,posFits$adSmooth - 2*posFits$adSmoothSE,
%           ##      col=j,lwd=3,lty=2)
%           ## Add Effects Predictions to Full DB:
%           keep2<-((uvDB$Exon==uExon[i])&(uvDB$replicate==uRep[j]))
%           temp2<-predict(gam.pos,newdata=uvDB[keep2,],se.fit=TRUE)
%           uvDB$adSmooth[keep2]<-temp2$fit
%           uvDB$adSmoothSE[keep2]<-temp2$se.fit
%       }
%       legend("topright",inset=0.01,col=c(1:length(uRep)),lwd=5,legend=uRep)
%       
%   }
%   dev.off()
%% end.rcode

\newpage
\section{Exploratory Mixed Effects Model of The Labeled Data}

\subsection{Setup Data Structure}

The following code chunk creates the final analysis data set and adds
the positionally normalized, logged day 14 to day 0 rate ratio and the
exon by replicate batch variable.  This structure becomes the new data
base matrix {\texttt{uvDB}}.  This structure is used for this
section's exploratory analysis and for the final VarCall analysis.

%% begin.rcode, fig.width=6.5, fig.height=4.0
%  ## Positional Normalization for Day 0:
%  uvDB$offset[uvDB$day=="D0"]<-(uvDB$offset[uvDB$day=="D0"]/exp(uvDB$adSmooth[uvDB$day=="D0"]))
%  D0<-uvDB[uvDB$day=="D0",]
%  D0$ID<-paste0(D0$variant,"_",D0$replicate)
%  length(unique(D0$ID))
%  D14<-uvDB[uvDB$day=="D14",]
%  D14$ID<-paste0(D14$variant,"_",D14$replicate)
%  length(unique(D14$ID))
%  table(D14$ID %in% D0$ID)
%  table(D0$ID %in% D14$ID)
%  D0<-D0[D0$ID %in% D14$ID,]
%  table(D0$ID == D14$ID)
%  #########################################################################
%  ## This is the Normalized log(Ratio) Used in the Classification Model: ##
%  #########################################################################
%  D14$lRatio<-(log(D14$count) - log(D14$offset)) - (log(D0$count) - log(D0$offset))
%  hist(D14$lRatio,nclass=100,main="Log Ratio")
%  ############################################
%  ## Data Set for Analysis of Labeled Data: ##
%  ############################################
%  uvKnown<-D14[!is.na(D14$label),]
%  #################################
%  ## Data Set for Full Analysis: ##
%  #################################
%  uvDB<-D14
%  uvDB$ER<-factor(uvDB$ER)
%  uvDB$batch<-as.numeric(uvDB$ER)  ## More refined batch variable
%  table(uvDB$ER)
%  table(uvDB$batch)
%% end.rcode

\subsection{Mixed Effects Model for the Labeled Variants}

Here we fit a linear mixed model using the labeled variants.  The
model includes a fixed effect for pathogenicity status
(\texttt{label}) and (nested) random effects for variant and exon and
random intercept for label.

%% begin.rcode, fig.width=3.5, fig.height=4.0
%  lme.out2<-lme(lRatio ~ -1 + label, random= ~ -1+label|Exon/variant,data=uvKnown)
%  summary(lme.out2)
%  re<-ranef(lme.out2)
%  names(re)
%  names(re[[2]])
%% end.rcode

In the following code chunk, we check modeling assumptions.

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
%  qqnorm(re[["Exon"]][,1],main="Benign Exon Effects")
%  abline(a=0,b=sd((re[["Exon"]][,1])),lwd=2,col=2)
%  qqnorm(re[["Exon"]][,2],main="Pathogenic Exon Effects")
%  abline(a=0,b=sd((re[["Exon"]][,2])),lwd=2,col=2)
%  qqnorm(re[["variant"]][,1],main="Variant Effects")
%  abline(a=0,b=sd((re[["variant"]][,1])),lwd=2,col=2)
%  qqnorm(residuals(lme.out2),main="Replicate Effects (Residuals)")
%  abline(a=0,b=sd(residuals(lme.out2)),lwd=2,col=2)
%% end.rcode

Looks like a t--distribution with approximately five degrees of
freedom might be needed for the measurement model:

%% begin.rcode, fig.width=7.5, fig.height=8.5
%  par(mfrow=c(2,2))
%  q<-qt(p=((1:nrow(uvKnown) - 0.5)/nrow(uvKnown)),df=5)
%  emp.q<-sort(residuals(lme.out2))
%  plot(q,emp.q,main="5df T for Residuals")
%  abline(a=0,b=coef(lm(emp.q~-1+q)),lwd=2,col=2)
%  boxplot(residuals(lme.out2)~uvKnown$Exon,main="Residuals by Exon")
%  ##boxplot(residuals(lme.out2)~uvKnown$p.b,main="Residuals by Pathogenicity")
%  boxplot(residuals(lme.out2)~uvKnown$label,main="Residuals by Pathogenicity")
%  ##boxplot(residuals(lme.out2)~uvKnown$Exon + uvKnown$p.b,
%  ##        main="Residuals by Exon and Pathogenicity")
%% end.rcode

\section{Setup Data Structures for Full VarCall Model}

This section creates the data structures needed for the JAGS
estimation procedure.

%% begin.rcode, fig.width=6.5, fig.height=8.5
%  ##kdel<-as.character(unique(uvMaster$uPOS[uvMaster$P_B=="P"]))
%  ##kneut<-as.character(unique(uvMaster$uPOS[uvMaster$P_B=="B"]))
%  kdel<-kdel[!is.na(kdel)]
%  kneut<-kneut[!is.na(kneut)]
%  length(kdel)
%  length(kneut)
%  known.ids<-c(kdel,kneut)
%  length(known.ids)
%  ##table(uvMaster$P_B)
%  table(uvMaster$label)
%% end.rcode

\subsection{Variant Labels}

%% begin.rcode, fig.width=6.5, fig.height=8.5
%  ########################################
%  ##  Create Structures for JAGS model: ##
%  ########################################
%  ##
%  ## (1) Variant Labels:
%  ##
%  num.b<-length(unique(uvDB$batch))
%  uvDB$variant<-factor(uvDB$variant)
%  ##known classifications:
%  known<-rep(0,length(uvDB$variant))
%  known[uvDB$variant%in%kdel]<-1     ## known disease associated variant
%  known[uvDB$variant%in%kneut]<-1    ## known disease neutral variant
%  uv.ids<-unique(levels(factor(uvDB$variant[known==0])))
%  length(known.ids)
%  length(uv.ids)
%  del.known<-rep(NA,length(uvDB$variant))
%  del.known[uvDB$variant%in%kdel]<-2
%  del.known[uvDB$variant%in%kneut]<-1
%  temp<-unique(cbind(as.character(uvDB$variant),as.numeric(uvDB$variant),del.known))
%  del.known<-temp[,3]
%  table(del.known)
%  v.ids<-as.character(temp[,1])
%  v.codes<-as.numeric(temp[,2])
%  names(del.known)<-v.ids
%  names(v.ids)<-v.ids
%  names(v.codes)<-v.ids
%  num.v<-length(v.ids)
%  ## Order variant codes 1 to n.var:
%  temp<-order(v.codes)
%  v.codes<-v.codes[temp]
%  v.ids<-v.ids[temp]
%  del.known<-del.known[temp]
%  table(v.codes==sort(v.codes))
%  table(diff(v.codes))
%  v.codes[1:4]
%% end.rcode

\section{JAGS Model Estimation and Summary Code}

\subsection{JAGS Data}

The structure {\texttt{bdat}} is a list containing the data needed for
fitting the VarCall model using JAGS.

%% begin.rcode, fig.width=6.5, fig.height=8.5
%      num.b<-length(unique(uvDB$batch))
%      uvDB$variant<-factor(uvDB$variant)
%      num.v<-length(v.ids)
%      eta0<-rep(NA,num.v)
%      alpha.value<-as.numeric(summary(lme.out2)$tTable[1:2,1])
%      bdat<-list(f.bv=uvDB$lRatio,tdf=t.df,
%                 batchM=uvDB$batch,
%                 variantM=as.numeric(uvDB$variant),
%                 del=as.integer(del.known),
%                 V=num.v, B=num.b,M=length(uvDB$lRatio),
%                 eta=eta0,a.pp=beta.a,b.pp=beta.b,
%                 alpha=alpha.value)
%% end.rcode

\subsection{Starting Values}

Here we specify a function for generating starting values
({\texttt{fun.inits()}}) and list of model structures
({\texttt{fun.parameters.bv}}) that we would like to `monitor.' JAGS
returns a matrix of samples from the posterior distribution for all
variables that are monitored.

%% begin.rcode, fig.width=6.5, fig.height=8.5
%      eta.start<-rnorm(num.v,0,0.25)
%      beta.start<-rnorm(num.b,0,0.01)
%      ## hist(beta.start)
%      del.start<-1+(eta.start<(-0.25))
%      del.start[!is.na(del.known)]<-NA
%      ## Parameters to Monitor
%      fun.parameters.bv <- c("del" , 
%                             "prob", "P", 
%                             "beta", "mu.beta",
%                             "sigma2.beta","gamma","mu.gamma","sigma2.gamma",
%                             "eta","sigma2.eta","sigma2.reps") 
%      ## Function that sets initial values:
%      fun.inits <- function(x=bv.leave.off.old) {
%          temp<-numeric(length(known.ids))
%          names(temp)<-known.ids
%          temp[known.ids %in% kdel]<-2
%          temp[known.ids %in% kneut]<-1
%          return(list(sigma.reps=0.01,
%                      beta=beta.start,
%                      sigma.beta=1.45,
%                      sigma.eta=c(0.50,0.50),
%                      eta=eta.start,sigma.gamma=0.05,mu.gamma=0.0,
%                      gamma=exp(rnorm(num.b,mean=0,sd=0.01)),
%                      mu.beta=0.0,
%                      del=del.start))
%      }
%% end.rcode

\subsection{Model Specification}

The MAVE VarCall model is specified in the external file {\texttt{maveModel.R}}:

%% begin.rcode
%  fun.model.file <- "maveModel.R"
%% end.rcode

\subsection{Fit Model}

Fit the model using MCMC.  {\textbf{NOTE: this code chunk may take hours to run
on a fast numerical server.}}

%% begin.rcode, mdlFit-cache, cache=TRUE, cache.lazy=FALSE
%  jags.out<-jags(data=bdat,   
%                 inits=fun.inits,  
%                 parameters=fun.parameters.bv,
%                 fun.model.file,
%                 n.chains=1, 
%                 n.iter=mcmc.pars$iter,
%                 n.burnin=mcmc.pars$burn,
%                 n.thin=mcmc.pars$thin,
%                 DIC=F,progress.bar="none")
%% end.rcode

\subsection{Model Summaries}

The matrix of sampled model parameter values is in the structure
{\texttt{jags.out$BUGSoutput$sims.matrix}}.  In the following code
chunk, we extract from this matrix blocks of key parameter values.
For example, as its name suggests, {\texttt{eta.samps}} contains
samples form the posterior distribution (rows) of the variant effect
(eta) values for each of the variants (columns).

%% begin.rcode, fig.width=3.5, fig.height=4.0
% dim(jags.out$BUGSoutput$sims.matrix)
% mpars1<-colnames(jags.out$BUGSoutput$sims.matrix)[substr(colnames(jags.out$BUGSoutput$sims.matrix),1,3)=="mu."]
% mu.samps<-jags.out$BUGSoutput$sims.matrix[,mpars1]
% mu.samps<-cbind(rep(bdat$alpha[1],nrow(mu.samps)),
%                 rep(bdat$alpha[2],nrow(mu.samps)),
%                 mu.samps)
% colnames(mu.samps)[1:2]<-c("alpha[1]","alpha[2]")
% rm(mpars1)
% var.samps<-jags.out$BUGSoutput$sims.matrix[,(substr(colnames(jags.out$BUGSoutput$sims.matrix),1,5)=="sigma")]
% beta.samps<-jags.out$BUGSoutput$sims.matrix[,paste("beta[",1:bdat$B,"]",sep="")]
% gamma.samps<-jags.out$BUGSoutput$sims.matrix[,paste("gamma[",1:bdat$B,"]",sep="")]
% eta.samps<-jags.out$BUGSoutput$sims.matrix[,paste("eta[",1:bdat$V,"]",sep="")]
% del.samps<-jags.out$BUGSoutput$sims.matrix[,paste("del[",1:bdat$V,"]",sep="")]
% colnames(eta.samps)<-v.ids
% colnames(del.samps)<-v.ids
%% end.rcode

The following code chunk we compute Rao--Blackwellized (RB) estimates of
the posterior probabilities that each variant is pathogenic.

%% begin.rcode, prdv-cache, cache=TRUE, cache.lazy=FALSE
% lpp.threshold<-100    
% subst<-(!(colnames(del.samps)%in%known.ids))
% prdv.samps<-fdv(eta.samps,m.s=mu.samps,
%                 v.s=var.samps,lpp.cap=lpp.threshold,
%                 prior.aa=beta.a,prior.bb=beta.b) 
% names(prdv.samps)
% names(prdv.samps$prdv)<-colnames(eta.samps)
% names(prdv.samps$lPostOdds)<-colnames(eta.samps) 
% names(prdv.samps$lBF)<-colnames(eta.samps)       
%% end.rcode

Here we compare the RB estimates to the Monte Carlo averages of the
binary variant--specific pathogenicity indicator variables (these two
sets of estimates should be very highly correlated):

%% begin.rcode, fig.width=3.5, fig.height=4.0
% subst<-(!(colnames(del.samps)%in%known.ids))
% del.hat<-(apply(del.samps,2,mean) - 1)
% cor(prdv.samps$prdv[subst],del.hat[subst])
% plot(prdv.samps$prdv[subst],del.hat[subst],
%      xlab="RB Estimates",ylab="MC Estimates",las=1)
% abline(a=0,b=1,col=4,lwd=2)
%% end.rcode

Plot histograms of the variant effects estimates (eta's) and the
estimated posterior probabilities of pathogenicity:

%% begin.rcode, fig.width=6.5, fig.height=7.0
% eta.hat<-(apply(eta.samps,2,mean))
% eta.ll<-(apply(eta.samps,2,quantile,probs=0.025))
% eta.ul<-(apply(eta.samps,2,quantile,probs=0.975))
% hist(del.hat,nclass=100,main="Estimated Pr(Path|Variant,Data)")
% hist(eta.hat,nclass=100,main="Estimated Variant Effects")
%% end.rcode

Check the observed distribution of the posterior expected standardized
measurement model residuals.  The model assumes a five degree of
freedom Student's t--distribution.  We provide QQ plots here for that
specification and three others:

%% begin.rcode, fig.width=6.5, fig.height=8.5
% mm.batch<-model.matrix(~-1+as.factor(bdat$batchM))
% mm.var<-model.matrix(~-1+as.factor(bdat$variantM))
% dim(mm.batch)
% dim(mm.var)
% dim(eta.samps)
% dim(beta.samps)
% lin.pred<-((gamma.samps%*%t(mm.batch))*(eta.samps%*%t(mm.var)))+(beta.samps%*%t(mm.batch))
% dim(lin.pred)
% lin.pred.v <- sweep(((gamma.samps^2)%*%t(mm.batch)),MARGIN=1,STATS=jags.out$BUGSoutput$sims.matrix[,"sigma2.reps"],FUN="*")
% lin.pred.sd<-sqrt(lin.pred.v)
% rm(lin.pred.v,mm.batch,mm.var)
% summary(as.numeric(apply(lin.pred.sd,2,mean)))
% expected.resids<-sweep(-lin.pred,MARGIN=2,STATS=bdat$f.bv,FUN="+")
% expected.resids<-apply(expected.resids,2,mean)
% lin.pred.sd<-apply(lin.pred.sd,2,mean)
% expected.stresids<-(expected.resids/lin.pred.sd)
% order.er<-order(expected.stresids)
% summary(expected.resids)
% lin.pred<-apply(lin.pred,2,mean)
% summary(lin.pred)
% par(mfrow=c(2,2))
% qqplot2(x=expected.stresids,tdf=101) ##normal qqplot w/ error bars
% qqplot2(x=expected.stresids,tdf=25) ##t-25 qqplot w/ error bars
% qqplot2(x=expected.stresids,tdf=10) ##t-10 qqplot w/ error bars
% qqplot2(x=expected.stresids,tdf=5) ##t-5 qqplot w/ error bars
%% end.rcode

Here is large rendering of the five degree of freedom QQ plot:

%% begin.rcode, fig.width=6.5, fig.height=8.5
% qqplot2(x=expected.stresids,tdf=5,
%         titl="Expected Standardized Residuals 5 df T Model")
%% end.rcode


Batch mean (beta's) and variant effect (eta's) normal QQ plots (note
the beta's are {\textit{not}} centered at zero):

%% begin.rcode, fig.width=7.5, fig.height=3.5
% ## Batch and Variant QQ plots.
% par(mfrow=c(1,2))
% ## (1) batch effects
% expected.batch.effects<-apply(beta.samps,2,mean)
% sd.batch.effects<-apply(beta.samps,2,sd)
% qqnorm(expected.batch.effects,main="Normal QQ Plot of Posterior Expected Batch Effects",las=1,cex.main=0.65) 
% abline(a=0,b=sd(expected.batch.effects))
% ## (2) variant effects, need to subtact mixture means, ie calc residuals:
% eta.mean<-sweep(1*(del.samps==1),1,STATS=mu.samps[,"alpha[1]"],FUN="*")+sweep(1*(del.samps==2),1,STATS=mu.samps[,"alpha[2]"],FUN="*")
% eta.var<-sweep(1*(del.samps==1),1,STATS=var.samps[,"sigma2.eta[1]"],FUN="*")+sweep(1*(del.samps==2),1,STATS=var.samps[,"sigma2.eta[2]"],FUN="*")
% eta.resids<-(eta.samps-eta.mean)/sqrt(eta.var)
% expected.eta.resids<-apply(eta.resids,2,mean)
% qqnorm(expected.eta.resids,main="Normal QQ Plot of Posterior Expected Variant Innovations",las=1,cex.main=0.65)
% abline(a=0,b=sd(expected.eta.resids))
%% end.rcode

Boxplots of the batch mean (beta's) and scale (gamma's) random effects
distributions:

%% begin.rcode, fig.width=6.5, fig.height=8.0
% batch.dm<-data.frame(batch=rep(1:ncol(beta.samps),each=nrow(beta.samps)),
%                      beta=matrix(beta.samps,ncol=1,byrow=F))
% par(mfrow=c(2,1))
% boxplot(beta~batch,data=batch.dm,las=2,cex.axis=0.60,outline=F,
%         pars=list(boxwex=0.6,crt=90),
%         main="Posterior distribution of Batch Offset Parameters",
%         ylab="Batch Offset",xlab="Batch Number",cex.main=0.75)
% abline(h=0,lwd=2,col=2)
% gamma.dm<-data.frame(batch=rep(1:ncol(gamma.samps),each=nrow(gamma.samps)),
%                      gamma=matrix(gamma.samps,ncol=1,byrow=F))
% boxplot(gamma~batch,data=gamma.dm,las=2,cex.axis=0.60,outline=F,
%         pars=list(boxwex=0.6,crt=90),
%         main="Posterior distribution of Batch Scale Parameters",
%         ylab="Batch Scale",xlab="Batch Number",cex.main=0.75)
% abline(h=1,lwd=2,col=2)
%% end.rcode

A scatter plot of posterior mean batch means vers batch scalings:

%% begin.rcode, fig.width=3.5, fig.height=4.0
% plot(apply(beta.samps,2,mean),apply(gamma.samps,2,mean),las=1,
%      xlab="Batch Offset",ylab="Batch Scale")
%% end.rcode

\subsection{Graphical Summaries of Parameter Estimates}

Histograms of the marginal posterior distributions of the variance
components: the measurment error squared scale parameter
{\texttt{sigma2.reps}}, the variance of the batch mean random effects
{\texttt{sigma2.beta}} and the variance of the logged batch scale
random effects {\texttt{sigma2.gamma}}.

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
% ## sigma2.reps
% hist(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.reps"]),cex.main=0.65,
%      prob=T,nclass=50,xlab="sigma2.reps",main="Prior versus Posterior -- sigma2.reps")
% lines(grid<-seq(0,max(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.reps"])),by=0.01),
%       2*dt(grid,df=1),col=3,lwd=2)
% ## sigma2.beta
% hist(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.beta"]),cex.main=0.65,
%      prob=T,nclass=50,xlab="sigma2.beta",main="Prior versus Posterior -- sigma2.beta")
% lines(grid<-seq(0,max(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.beta"])),by=0.01),
%       2*dt(grid,df=1),col=3,lwd=2)
% ## sigma2.gamma
% hist(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.gamma"]),cex.main=0.65,
%      prob=T,nclass=50,xlab="sigma^2_gamma",main="Prior versus Posterior -- sigma2.gamma")
% lines(grid<-seq(0,max(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.gamma"])),by=0.01),
%       2*dt(grid,df=1),col=3,lwd=2)
%% end.rcode

Histograms of the marginal posterior distributions of the
component--wise variances (they are constrained to be equal) for the
two--component normal mixture model for the variant effects (eta's).

%% begin.rcode, fig.width=7.5, fig.height=4.5
% par(mfrow=c(1,2))
% ## sigma2.eta[1]
% hist(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.eta[1]"]),cex.main=0.65,
%      prob=T,nclass=50,xlab="sigma.eta[1]",main="Prior versus Posterior -- sigma.eta[1]")
% lines(grid<-seq(0,max(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.eta[1]"])),by=0.01),
%       2*dt(grid,df=1),col=3,lwd=2)
% ## sigma2.eta[2]
% hist(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.eta[2]"]),cex.main=0.65,
%      prob=T,nclass=50,xlab="sigma.eta[2] == sigma.eta[1]",
%      main="Prior versus Posterior -- sigma_eta[2]==sigma_eta[1]")
% lines(grid<-seq(0,max(sqrt(jags.out$BUGSoutput$sims.matrix[,"sigma2.eta[2]"])),by=0.01),
%       2*dt(grid,df=1),col=3,lwd=2)
%% end.rcode

Histograms of the marginal posterior distributions of the mean of the
batch mean parameters (\texttt{mu.beta}) and the mean of the logged
batch scale parameters ({\texttt{mu.gamma}}).

%% begin.rcode, fig.width=7.5, fig.height=4.5
% ##Mean parameters:
% par(mfrow=c(1,2))
% ## mu.beta
% hist(jags.out$BUGSoutput$sims.matrix[,"mu.beta"],cex.main=0.85,
%      prob=T,nclass=50,xlab="mu.beta",
%      main="Prior versus Posterior -- mu.beta")
% abline(h=(1/20),col=3,lwd=2)
% ## mu.gamma
% hist(jags.out$BUGSoutput$sims.matrix[,"mu.gamma"],cex.main=0.85,
%      prob=T,nclass=50,xlab="mu.gamma",
%      main="Prior versus Posterior -- mu.gamma")
% lines(grid<-seq(min(jags.out$BUGSoutput$sims.matrix[,"mu.gamma"]),
%                 max(jags.out$BUGSoutput$sims.matrix[,"mu.gamma"]),by=0.01),
%      2*dnorm(grid,mean=0,sd=1),col=3,lwd=2)
%% end.rcode

\subsection{Table of Estimated Variant Effects}

Assemble a table of variant--level results for export:

%% begin.rcode, fig.width=7.5, fig.height=8.5
% pr.del<-prdv.samps$prdv
% length(pr.del)
% pr.del[1:3]
% tabl<-annot
% colnames(tabl)[2]<-"variant"
% dim(tabl)
% length(unique(tabl$variant))
% rownames(tabl)<-tabl$variant
% tabl<-data.frame(tabl)
% tabl$PrDel<-rep(NA,nrow(tabl))
% table(names(pr.del) %in% rownames(tabl))
% tabl[names(pr.del),"PrDel"]<-pr.del
% table(tabl$P_B[is.na(tabl$PrDel)])
% table(tabl$P_B[!is.na(tabl$PrDel)])
% lp.odds<-prdv.samps$lPostOdds
% tabl$lPostOdds<-rep(NA,nrow(tabl))
% table(names(lp.odds) %in% rownames(tabl))
% tabl[names(lp.odds),"lPostOdds"]<-lp.odds
% lbf<-prdv.samps$lBF
% tabl$logBF<-rep(NA,nrow(tabl))
% table(names(lbf) %in% rownames(tabl))
% tabl[names(lbf),"logBF"]<-lbf
% tabl$Status<-rep("VUS",nrow(tabl))
% tabl$Status[rownames(tabl)%in%kdel]<-"Path"
% tabl$Status[rownames(tabl)%in%kneut]<-"Neut"
% table(tabl$Status)
% temp<-apply(eta.samps,2,mean,na.rm=TRUE)
% temp<-temp[rownames(tabl)]
% table(names(temp) == rownames(tabl))
% tabl$eta <- temp; rm(temp)
% eta.ll<-(apply(eta.samps,2,quantile,probs=0.025))
% eta.ul<-(apply(eta.samps,2,quantile,probs=0.975))
% tabl$eta.ll<-rep(NA,nrow(tabl))
% tabl[names(eta.ll),"eta.ll"]<-eta.ll
% tabl$eta.ul<-rep(NA,nrow(tabl))
% tabl[names(eta.ul),"eta.ul"]<-eta.ul
%% end.rcode

%% begin.rcode
%  ## Output Table of Estimates:
%  write.table(tabl,file="MAVEpostProbs.csv",quote=FALSE,sep=",",row.names=FALSE,col.names=TRUE)
%% end.rcode

\section{Plots of Supplemental Materials}

These are individual plots for use in the supplement:

%% begin.rcode
%  pdf("ResidualQQ.pdf",width=8,height=8)
%  qqplot2(x=expected.stresids,tdf=5,
%          titl="Expected Standardized Residuals 5 df T Model")
%  dev.off()
%  
%  pdf("PrDelHistogram.pdf",width=8,height=8)
%  hist(del.hat,nclass=100,
%       main="Estimated Pr(Path | Variant, Data)\n All Assayed Variants",
%       las=1)
%  dev.off()
%  
%  pdf("EtaHistogram.pdf",width=8,height=6)
%  hist(eta.hat,nclass=100,cex.main=1.4,
%       main="Estimated Variant Effects (Eta's)\n All Assayed Variants",
%       las=1)
%  dev.off()
%  
%  pdf("BatchMeanQQ.pdf",width=8,height=8)
%  qqplot2(expected.batch.effects,tdf=1000,
%         titl="Normal QQ Plot of Posterior Expected Batch Mean Effects")
%  dev.off()
%  
%  batch.scale.effects<-log(apply(gamma.samps,2,mean))
%  pdf("BatchScaleQQ.pdf",width=8,height=8)
%  qqplot2(batch.scale.effects,tdf=1000,
%         titl="Normal QQ Plot of Posterior Logged Expected Scale Effects")
%  dev.off()
%  
%  pdf("VariantQQ.pdf",width=8,height=8)
%  qqplot2(expected.eta.resids,tdf=1000,
%          titl="Normal QQ Plot of Posterior Expected Mean--Adjusted Variant Innovations")
%  dev.off()
%  
%  pdf("BatchMeanBPlot.pdf",width=10,height=6)
%  boxplot(beta~batch,data=batch.dm,las=2,outline=F,
%           pars=list(boxwex=0.6,crt=90),
%          main="Posterior distribution of Batch Mean Parameters `Beta'",
%          ylab="Batch Mean",xlab="Batch Number",cex.main=1.5)
%  abline(h=0,lwd=2,col=2)
%  dev.off()
%  
%  pdf("BatchScaleBPlot.pdf",width=10,height=6)
%  boxplot(gamma~batch,data=gamma.dm,las=2,cex.axis=0.60,outline=F,
%          pars=list(boxwex=0.6,crt=90),
%          main="Posterior distribution of Batch Scale Parameters `Gamma'",
%          ylab="Batch Scale",xlab="Batch Number",cex.main=1.5)
%  abline(h=1,lwd=2,col=2)
%  dev.off()
%  
%  pdf("BatchLocationVsScale.pdf",width=8,height=8)
%  plot(apply(beta.samps,2,mean),apply(gamma.samps,2,mean),las=1,
%       main="Scatter Plot of Batch Mean Versus Scale Adjustments",
%       xlab="Batch Mean",ylab="Batch Scale",pch=16)
%  dev.off()
%% end.rcode

\section{Wrap--Up}

%% begin.rcode
%  gc(); save.image()
%% end.rcode

\end{document}




%% begin.rcode, fig.width=6.5, fig.height=8.5
%% end.rcode


%% begin.rcode, fig.width=7.5, fig.height=3.5
%% end.rcode

%% begin.rcode, fig.width=6.5, fig.height=8.0
%% end.rcode

%% begin.rcode, fig.width=3.5, fig.height=4.0
%% end.rcode

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
%% end.rcode

%% begin.rcode, fig.width=7.5, fig.height=8.5
% par(mfrow=c(2,2))
%% end.rcode

% end.rcode
